{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d360e-140d-4843-a850-b511214a1a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:00.104081Z",
     "iopub.status.busy": "2023-05-04T06:57:00.102704Z",
     "iopub.status.idle": "2023-05-04T06:57:01.032238Z",
     "shell.execute_reply": "2023-05-04T06:57:01.032238Z",
     "shell.execute_reply.started": "2023-05-04T06:57:00.104081Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1696c-2242-4b21-97dc-2e28ac170e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:02.371978Z",
     "iopub.status.busy": "2023-05-04T06:57:02.371978Z",
     "iopub.status.idle": "2023-05-04T06:57:02.386981Z",
     "shell.execute_reply": "2023-05-04T06:57:02.386981Z",
     "shell.execute_reply.started": "2023-05-04T06:57:02.371978Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "kapa = 0.0057 # values obtained from theoretical model\n",
    "tao = 0.0013\n",
    "diffl = 157.4158\n",
    "layers = np.array([1, 100, 100, 100, 100, 100, 4])\n",
    "N_f = 2000\n",
    "N_u = 1\n",
    "N_t = 100\n",
    "steps = 42000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec3018-512d-4150-96b5-8c416d930437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:02.721128Z",
     "iopub.status.busy": "2023-05-04T06:57:02.721128Z",
     "iopub.status.idle": "2023-05-04T06:57:03.785433Z",
     "shell.execute_reply": "2023-05-04T06:57:03.785433Z",
     "shell.execute_reply.started": "2023-05-04T06:57:02.721128Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kapa = torch.tensor([kapa], requires_grad = True).float().to(device)\n",
    "tao = torch.tensor([tao], requires_grad = True).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b2b9c-097f-42e6-a645-22e104a72074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:03.800619Z",
     "iopub.status.busy": "2023-05-04T06:57:03.800619Z",
     "iopub.status.idle": "2023-05-04T06:57:03.832335Z",
     "shell.execute_reply": "2023-05-04T06:57:03.832335Z",
     "shell.execute_reply.started": "2023-05-04T06:57:03.800619Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FCN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        self.loss_function = torch.nn.MSELoss(reduction = \"mean\")\n",
    "        self.linears1 = torch.nn.ModuleList([torch.nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.linears2 = torch.nn.ModuleList([torch.nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)]) \n",
    "        self.linears3 = torch.nn.ModuleList([torch.nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)]) \n",
    "        \n",
    "        self.iter = 0\n",
    "        for i in range(len(layers)-1):\n",
    "            torch.nn.init.xavier_normal_(self.linears1[i].weight.data, gain=1.0)\n",
    "            torch.nn.init.zeros_(self.linears1[i].bias.data)\n",
    "            torch.nn.init.xavier_normal_(self.linears2[i].weight.data, gain=1.0)\n",
    "            torch.nn.init.zeros_(self.linears2[i].bias.data)\n",
    "            torch.nn.init.xavier_normal_(self.linears3[i].weight.data, gain=1.0)\n",
    "            torch.nn.init.zeros_(self.linears3[i].bias.data)\n",
    "        \n",
    "        self.kapa = torch.nn.Parameter(kapa)\n",
    "        self.tao = torch.nn.Parameter(tao)\n",
    "        \n",
    "    def forward1(self, x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)\n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "        x = (x - l_b)/(u_b - l_b)\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-3):\n",
    "            identity = a\n",
    "            z = self.linears1[i](a)\n",
    "            # z = z + identity\n",
    "            a = torch.cos(z)\n",
    "            a = a + identity\n",
    "        identity = a\n",
    "        z = self.linears1[-2](a)\n",
    "        # z = z + identity\n",
    "        a = torch.cos(z)\n",
    "        a = a + identity\n",
    "        a = self.linears1[-1](a)\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    def forward2(self, x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)\n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "        x = (x - l_b)/(u_b - l_b)\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-3):\n",
    "            identity = a\n",
    "            z = self.linears2[i](a)\n",
    "            # z = z + identity\n",
    "            a = torch.sin(z)\n",
    "            a = a + identity\n",
    "        identity = a\n",
    "        z = self.linears2[-2](a)\n",
    "        # z = z + identity\n",
    "        a = torch.sin(z)\n",
    "        a = a + identity\n",
    "        a = self.linears2[-1](a)\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    def forward3(self, x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)\n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "        x = (x - l_b)/(u_b - l_b)\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            identity = a\n",
    "            z = self.linears3[i](a)\n",
    "            # z = z + identity\n",
    "            a = self.activation(z)\n",
    "            a = a + identity\n",
    "        a = self.linears3[-1](a)\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    def loss_data(self, X_data, U_data):\n",
    "        x = self.forward1(X_data)\n",
    "        y = self.forward2(X_data)\n",
    "        z = self.forward3(X_data)\n",
    "        \n",
    "        x_error = self.loss_function(x[:, 0:1], U_data[:, 0:1])\n",
    "        y_error = self.loss_function(y[:, 0:1], U_data[:, 1:2])\n",
    "        z_error = self.loss_function(z[:, 0:1], U_data[:, 2:3])\n",
    "        \n",
    "        loss_d = x_error + y_error + z_error\n",
    "        \n",
    "        return loss_d\n",
    "    \n",
    "    def loss_BC(self, X_train_Nu, U_train_Nu):\n",
    "        x = self.forward1(X_train_Nu).reshape((1, 4))\n",
    "        y = self.forward2(X_train_Nu).reshape((1, 4))\n",
    "        z = self.forward3(X_train_Nu).reshape((1, 4))\n",
    "        loss_u1 = self.loss_function(x[:, 0:1], U_train_Nu[:, 0:1])\n",
    "        loss_u2 = self.loss_function(y[:, 0:1], U_train_Nu[:, 1:2])\n",
    "        loss_u3 = self.loss_function(z[:, 0:1], U_train_Nu[:, 2:3])\n",
    "        \n",
    "        loss_u = loss_u1 + loss_u2 + loss_u3\n",
    "        \n",
    "        return loss_u\n",
    "    \n",
    "    def loss_ODE(self, X_train_Nf):\n",
    "        kapa = self.kapa\n",
    "        tao = self.tao\n",
    "        \n",
    "        g = X_train_Nf.clone()\n",
    "        g.requires_grad = True\n",
    "        \n",
    "        x = self.forward1(g) #[1001, 4]\n",
    "        y = self.forward2(g)\n",
    "        z = self.forward3(g)\n",
    "        \n",
    "        x1_grad = torch.autograd.grad(x[:, 0:1], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        x2_grad = torch.autograd.grad(x[:, 1:2], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        x3_grad = torch.autograd.grad(x[:, 2:3], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        x4_grad = torch.autograd.grad(x[:, 3:4], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        y1_grad = torch.autograd.grad(y[:, 0:1], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        y2_grad = torch.autograd.grad(y[:, 1:2], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        y3_grad = torch.autograd.grad(y[:, 2:3], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        y4_grad = torch.autograd.grad(y[:, 3:4], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        z1_grad = torch.autograd.grad(z[:, 0:1], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        z2_grad = torch.autograd.grad(z[:, 1:2], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        z3_grad = torch.autograd.grad(z[:, 2:3], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        z4_grad = torch.autograd.grad(z[:, 3:4], g, torch.ones([X_train_Nf.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        f1 = x1_grad - y[:, 1:2] * diffl\n",
    "        f2 = y1_grad - x[:, 1:2] * diffl\n",
    "        f3 = z1_grad - z[:, 1:2] * diffl\n",
    "        f4 = x2_grad - kapa * y[:, 2:3] * diffl\n",
    "        f5 = y2_grad - kapa * x[:, 2:3] * diffl\n",
    "        f6 = z2_grad - kapa * z[:, 2:3] * diffl\n",
    "        f7 = x3_grad - (- kapa * y[:, 1:2] + tao * y[:, 3:4]) * diffl\n",
    "        f8 = y3_grad - (- kapa * x[:, 1:2] + tao * x[:, 3:4]) * diffl\n",
    "        f9 = z3_grad - (- kapa * z[:, 1:2] + tao * z[:, 3:4]) * diffl\n",
    "        f10 = x4_grad + tao * y[:, 2:3] * diffl\n",
    "        f11 = y4_grad + tao * x[:, 2:3] * diffl\n",
    "        f12 = z4_grad + tao * z[:, 2:3] * diffl\n",
    "        \n",
    "        loss_f1 = self.loss_function(f1, f_hat)\n",
    "        loss_f2 = self.loss_function(f2, f_hat)\n",
    "        loss_f3 = self.loss_function(f3, f_hat)\n",
    "        loss_f4 = self.loss_function(f4, f_hat)\n",
    "        loss_f5 = self.loss_function(f5, f_hat)\n",
    "        loss_f6 = self.loss_function(f6, f_hat)\n",
    "        loss_f7 = self.loss_function(f7, f_hat)\n",
    "        loss_f8 = self.loss_function(f8, f_hat)\n",
    "        loss_f9 = self.loss_function(f9, f_hat)\n",
    "        loss_f10 = self.loss_function(f10, f_hat)\n",
    "        loss_f11 = self.loss_function(f11, f_hat)\n",
    "        loss_f12 = self.loss_function(f12, f_hat)\n",
    "        \n",
    "        loss_f = loss_f1 + loss_f2 + loss_f3 + loss_f4 + loss_f5 + loss_f6 + loss_f7 + loss_f8 + loss_f9 + loss_f10 + loss_f11 + loss_f12\n",
    "        \n",
    "        return loss_f\n",
    "    \n",
    "    def loss_vector(self, X_train_Nf):\n",
    "        g = X_train_Nf.clone()\n",
    "        g.requires_grad = True\n",
    "        \n",
    "        x = self.forward1(g)\n",
    "        y = self.forward2(g)\n",
    "        z = self.forward3(g)\n",
    "        \n",
    "        loss_v1 = 1 - torch.sqrt(torch.pow(x[:, 1:2], 2) + torch.pow(y[:, 1:2], 2) + torch.pow(z[:, 1:2], 2) + 1e-10)\n",
    "        loss_v2 = 1 - torch.sqrt(torch.pow(x[:, 2:3], 2) + torch.pow(y[:, 2:3], 2) + torch.pow(z[:, 2:3], 2) + 1e-10)\n",
    "        loss_v3 = 1 - torch.sqrt(torch.pow(x[:, 3:4], 2) + torch.pow(y[:, 3:4], 2) + torch.pow(z[:, 3:4], 2) + 1e-10)\n",
    "        \n",
    "        loss_f13 = self.loss_function(loss_v1, f_hat)\n",
    "        loss_f14 = self.loss_function(loss_v2, f_hat)\n",
    "        loss_f15 = self.loss_function(loss_v3, f_hat)\n",
    "    \n",
    "        loss_v = loss_f13 + loss_f14 + loss_f15\n",
    "        \n",
    "        return loss_v\n",
    "    \n",
    "    def loss(self, X_train_Nu, U_train_Nu, X_train_Nf, X_data, U_data):\n",
    "        loss_u = self.loss_BC(X_train_Nu, U_train_Nu)\n",
    "        loss_f = self.loss_ODE(X_train_Nf)\n",
    "        loss_d = self.loss_data(X_data, U_data)\n",
    "        loss_v = self.loss_vector(X_train_Nf)\n",
    "        \n",
    "        loss_val = 10 * loss_u + loss_f + loss_d + 4 * loss_v\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def closure(self):\n",
    "        optimizer.zero_grad()  \n",
    "        loss = self.loss(X_train_Nu, U_train_Nu, X_train_Nf, X_data, U_data)\n",
    "        loss.backward()      \n",
    "        self.iter += 1\n",
    "        if self.iter % 1000 == 0:\n",
    "            print(\"Training Error:\",loss.detach().cpu().numpy())\n",
    "        \n",
    "        return loss \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b15f4-3e39-48e4-915c-0c2092ad28e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:03.832335Z",
     "iopub.status.busy": "2023-05-04T06:57:03.832335Z",
     "iopub.status.idle": "2023-05-04T06:57:04.421319Z",
     "shell.execute_reply": "2023-05-04T06:57:04.421319Z",
     "shell.execute_reply.started": "2023-05-04T06:57:03.832335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyDOE import lhs \n",
    "ub = np.array([9.65])\n",
    "lb = np.array([0])\n",
    "\n",
    "X_train_Nu = np.array([0]).reshape((1, 1))\n",
    "X_train_Nf = lb + (ub - lb)*lhs(1, N_f) \n",
    "X_train_Nf = np.vstack((X_train_Nf, X_train_Nu))\n",
    "U_train_Nu = np.array([0, 0, 0]).reshape((1, 3))\n",
    "X_train_Nt = lb + (ub - lb) * lhs(1, N_t)\n",
    "\n",
    "\n",
    "data = pd.read_excel('data1.xlsx', header = None).to_numpy()\n",
    "X_data = data[:, 0].reshape((11, 1))\n",
    "U_data = data[:, 1:4].reshape((11, 3))\n",
    "print(X_data.shape)\n",
    "print(U_data.shape)\n",
    "print(X_train_Nf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f41af-e867-448e-bee5-398faea9ee4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:04.421319Z",
     "iopub.status.busy": "2023-05-04T06:57:04.421319Z",
     "iopub.status.idle": "2023-05-04T06:57:04.431199Z",
     "shell.execute_reply": "2023-05-04T06:57:04.431199Z",
     "shell.execute_reply.started": "2023-05-04T06:57:04.421319Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_Nf = torch.from_numpy(X_train_Nf).float().to(device)\n",
    "X_train_Nu = torch.from_numpy(X_train_Nu).float().to(device)\n",
    "U_train_Nu = torch.from_numpy(U_train_Nu).float().to(device)\n",
    "X_train_Nt = torch.from_numpy(X_train_Nt).float().to(device)\n",
    "f_hat = torch.zeros(X_train_Nf.shape[0], 1).to(device)\n",
    "f_hat_t = torch.zeros(X_train_Nt.shape[0], 1).to(device)\n",
    "X_data = torch.from_numpy(X_data).float().to(device)\n",
    "U_data = torch.from_numpy(U_data).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe6c39-0f4d-43b6-a73c-7138d0b22215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:04.487713Z",
     "iopub.status.busy": "2023-05-04T06:57:04.487713Z",
     "iopub.status.idle": "2023-05-04T06:57:04.502835Z",
     "shell.execute_reply": "2023-05-04T06:57:04.501771Z",
     "shell.execute_reply.started": "2023-05-04T06:57:04.487713Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_Nf, _ = torch.sort(X_train_Nf, dim = 0)\n",
    "X_train_Nt, _ = torch.sort(X_train_Nt, dim = 0)\n",
    "print(X_train_Nf.shape)\n",
    "print(X_train_Nu.shape)\n",
    "print(U_train_Nu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dad46-d7c4-4380-99a2-e24840d3535f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:04.503843Z",
     "iopub.status.busy": "2023-05-04T06:57:04.503843Z",
     "iopub.status.idle": "2023-05-04T06:57:04.606385Z",
     "shell.execute_reply": "2023-05-04T06:57:04.606385Z",
     "shell.execute_reply.started": "2023-05-04T06:57:04.503843Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "springbackcurve = pd.read_excel('springbackcurve830.xlsx', header = None).to_numpy()\n",
    "springbackcurve = torch.from_numpy(springbackcurve[:, 0:3]).float().to(device)\n",
    "p = pd.read_excel('point830.xlsx', header = None).to_numpy()\n",
    "\n",
    "p = torch.from_numpy(p).float().to(device)\n",
    "def curve_error(springbackcurve, pre_curve):\n",
    "    subs = pre_curve - springbackcurve\n",
    "    disVector = torch.sqrt(torch.pow(subs[:, 0:1], 2) + torch.pow(subs[:, 1:2], 2) + torch.pow(subs[:, 2:3], 2))\n",
    "    i = torch.arange(1, 363)\n",
    "    i = i.reshape((362, 1)).to(device)\n",
    "    error_dis = disVector[1:362, 0:1] / (1.5 * (i[1:362, 0:1] - 1))\n",
    "    error = torch.sqrt(torch.sum(torch.pow(error_dis, 2)) / disVector.shape[0])\n",
    "    return error\n",
    "\n",
    "def ED(springbackcurve, pre_curve):\n",
    "    subs = pre_curve - springbackcurve\n",
    "    distance = torch.norm(subs, dim = 1)\n",
    "    mean_dis = torch.mean(distance)\n",
    "    return mean_dis\n",
    "\n",
    "def DTW(springbackcurve, pre_curve):\n",
    "    m, n = springbackcurve.shape[0], pre_curve.shape[0]\n",
    "    dp = torch.zeros((m + 1, n + 1))\n",
    "    dp[0, 1:] = float('inf')\n",
    "    dp[1:, 0] = float('inf')\n",
    "    dp[1:, 1:] = torch.cdist(springbackcurve, pre_curve, p = 2)\n",
    "    dp1 = dp[1:, 1:]\n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            dp1[i, j] += min(dp[i, j], dp[i, j + 1], dp[i + 1, j])\n",
    "            \n",
    "    return dp1[-1, -1] / sum(dp1.shape)\n",
    "    \n",
    "def LCSS(springbackcurve, pre_curve):\n",
    "    eps = 1\n",
    "    delta = 5\n",
    "    m, n = springbackcurve.shape[0], pre_curve.shape[0]\n",
    "    dp = torch.zeros((m + 1, n + 1))\n",
    "    dist = torch.cdist(springbackcurve, pre_curve, p = 2)\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if dist[i - 1, j - 1] <= eps:\n",
    "                dp[i, j] = dp[i - 1, j - 1] + 1\n",
    "            else:\n",
    "                dp[i, j] = max(dp[i - 1, j], dp[i, j - 1])\n",
    "            if abs(i - j) > delta:\n",
    "                dp[i, j] = 0\n",
    "    \n",
    "    return dp[-1, -1] / m\n",
    "\n",
    "from frechetdist import frdist\n",
    "def Frechet(springbackcurve, pre_curve):\n",
    "    frechet = frdist(springbackcurve, pre_curve)\n",
    "    return frechet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca591223-0103-4e35-a50d-1036c743d1bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:04.685505Z",
     "iopub.status.busy": "2023-05-04T06:57:04.685505Z",
     "iopub.status.idle": "2023-05-04T06:57:04.698001Z",
     "shell.execute_reply": "2023-05-04T06:57:04.698001Z",
     "shell.execute_reply.started": "2023-05-04T06:57:04.685505Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "PINN = FCN(layers)\n",
    "PINN.to(device)\n",
    "print(PINN)\n",
    "params = list(PINN.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(PINN.parameters(),lr=lr,amsgrad=False)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10000, gamma = 0.5)\n",
    "# print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024360f8-8415-401b-9475-eeccaa5e521f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:05.121350Z",
     "iopub.status.busy": "2023-05-04T06:57:05.121350Z",
     "iopub.status.idle": "2023-05-04T06:57:05.135592Z",
     "shell.execute_reply": "2023-05-04T06:57:05.135592Z",
     "shell.execute_reply.started": "2023-05-04T06:57:05.121350Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_loss = np.array(0.1)\n",
    "min_loss = torch.from_numpy(min_loss).float().to(device)\n",
    "loss_list = []\n",
    "error_list = []\n",
    "grad_store = []\n",
    "error_ED_list = []\n",
    "error_DTW_list = []\n",
    "error_LCSS_list = []\n",
    "error_F_list = []\n",
    "kapa_list = []\n",
    "tao_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ceda15-cea6-4d3e-8401-55ce329d5ecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:57:05.532757Z",
     "iopub.status.busy": "2023-05-04T06:57:05.532757Z",
     "iopub.status.idle": "2023-05-04T08:03:02.322196Z",
     "shell.execute_reply": "2023-05-04T08:03:02.322196Z",
     "shell.execute_reply.started": "2023-05-04T06:57:05.532757Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(steps):\n",
    "    loss = PINN.loss(X_train_Nu, U_train_Nu, X_train_Nf, X_data, U_data)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        PINN.kapa.clamp_(0.002, 0.01)\n",
    "        PINN.tao.clamp_(0.0008, 0.002)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    pre_curve_all_x = PINN.forward1(p)\n",
    "    pre_curve_all_y = PINN.forward2(p)\n",
    "    pre_curve_all_z = PINN.forward3(p)\n",
    "    pre_curve_all = torch.hstack((pre_curve_all_x[:, 0:1], pre_curve_all_y[:, 0:1], pre_curve_all_z[:, 0:1]))\n",
    "    pre_curve = pre_curve_all[:, 0:3]\n",
    "    error = curve_error(springbackcurve, pre_curve)\n",
    "    error_list.append(error.item())\n",
    "    kapa_list.append(kapa.item())\n",
    "    tao_list.append(tao.item())\n",
    "    \n",
    "    #损失函数记录\n",
    "    if i % 400 == 0:\n",
    "        pre_curve_c = pre_curve.cpu()\n",
    "        springbackcurve_c = springbackcurve.cpu()\n",
    "        error_ED = ED(springbackcurve_c, pre_curve_c)\n",
    "        error_DTW = DTW(springbackcurve_c, pre_curve_c)\n",
    "        error_LCSS = LCSS(springbackcurve_c, pre_curve_c)\n",
    "        error_F = Frechet(springbackcurve_c.detach().numpy(), pre_curve_c.detach().numpy())\n",
    "        error_ED_list.append(error_ED.item())\n",
    "        error_DTW_list.append(error_DTW.item())\n",
    "        error_LCSS_list.append(error_LCSS.item())\n",
    "        error_F_list.append(error_F)\n",
    "        \n",
    "    loss_list.append(loss.item())\n",
    "    \n",
    "    if i % 2000 == 0:\n",
    "        # test = PINN.test(X_train_Nu, U_train_Nu, X_train_Nt, X_data, U_data)\n",
    "        test_BC = PINN.loss_BC(X_train_Nu, U_train_Nu)\n",
    "        print(\" loss: \", loss.detach().cpu().numpy(), \"  test_BC loss: \", test_BC.detach().cpu().numpy(), \"  error: \", error.detach().cpu().numpy())\n",
    "        print(\" error_ED is: \", error_ED, \" error_DTW is: \", error_DTW, \" error_LCSS is: \", error_LCSS, \" error_F is: \", error_F)\n",
    "        print(\"kapa: \", PINN.kapa, \"  tao: \", PINN.tao)\n",
    "        print('**********************************************************************************************' + str(i))\n",
    "    \n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "        torch.save(PINN.state_dict(), 'modelzi.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = PINN.forward1(X_train_Nf) #[1001, 4]\n",
    "y = PINN.forward2(X_train_Nf)\n",
    "z = PINN.forward3(X_train_Nf)\n",
    "test = torch.hstack((x[:, 0:1], y[:, 0:1], z[:, 0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a81060",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train_Nf.detach().cpu().numpy(), x[:, 3].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = test.detach().cpu().numpy()\n",
    "c = springbackcurve.detach().cpu().numpy()\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection = '3d')\n",
    "ax.plot3D(b[:, 0:1], b[:, 1:2], b[:, 2:3], 'red')\n",
    "ax.plot3D(c[:, 0:1], c[:, 1:2], c[:, 2:3], 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca734f0-ae48-4a50-b4ce-0d8b3ec31321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9bd2f-f997-4e5d-8afa-ab6fb87855c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
